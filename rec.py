# refactored_app.py

import requests
import streamlit as st
import cv2
import numpy as np
from sklearn.cluster import KMeans
import torch
from PIL import Image
import os
import json
import re

# --- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from mobile_sam import sam_model_registry, SamPredictor
from streamlit_drawable_canvas import st_canvas

# --- 2. ìƒìˆ˜ ì •ì˜ ---
# íŒŒì¼ ê²½ë¡œë“¤ì„ ìƒë‹¨ì— ìƒìˆ˜ë¡œ ì •ì˜í•˜ì—¬ ê´€ë¦¬ ìš©ì´ì„±ì„ ë†’ì…ë‹ˆë‹¤.
IMAGE_PATH = "input.jpg"
MODEL_PATH = "mobile_sam.pt"
JSON_PATH = "colors_lab.json"

# ===================================================================
# í—¬í¼ í•¨ìˆ˜ (Helper Functions)
# ===================================================================

def normalize_brightness(image_bgr: np.ndarray) -> np.ndarray:
    """HSV ìƒ‰ìƒ ê³µê°„ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ë°ê¸°ë¥¼ í‰íƒ„í™”í•©ë‹ˆë‹¤."""
    image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(image_hsv)
    v_eq = cv2.equalizeHist(v)
    image_hsv_eq = cv2.merge([h, s, v_eq])
    return cv2.cvtColor(image_hsv_eq, cv2.COLOR_HSV2BGR)

def extract_lab_palette(image_bgr: np.ndarray, mask: np.ndarray, n_colors: int = 5) -> np.ndarray:
    """ë§ˆìŠ¤í¬ ì˜ì—­ì—ì„œ LAB ìƒ‰ìƒ íŒ”ë ˆíŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    pixels_in_mask = image_bgr[mask]
    if len(pixels_in_mask) == 0:
        raise ValueError("ë§ˆìŠ¤í¬ ì˜ì—­ì— í”½ì…€ì´ ì—†ìŠµë‹ˆë‹¤.")
    masked_lab = cv2.cvtColor(pixels_in_mask.reshape(-1, 1, 3), cv2.COLOR_BGR2Lab).reshape(-1, 3)
    kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)
    kmeans.fit(masked_lab)
    return kmeans.cluster_centers_

def create_palette_image(lab_colors: np.ndarray, block_size: tuple = (50, 50)) -> np.ndarray:
    """LAB ìƒ‰ìƒ ë°°ì—´ë¡œ íŒ”ë ˆíŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    bgr_colors = []
    for c in lab_colors:
        L, a, b = np.clip(c, 0, 255)
        lab_pixel = np.uint8([[[L, a, b]]])
        bgr = cv2.cvtColor(lab_pixel, cv2.COLOR_Lab2BGR)[0, 0]
        bgr_colors.append(bgr)
    h, w = block_size[1], block_size[0] * len(bgr_colors)
    palette_img = np.zeros((h, w, 3), dtype=np.uint8)
    for i, color in enumerate(bgr_colors):
        palette_img[:, i * block_size[0]:(i + 1) * 100] = color
    return palette_img

def calc_distance(lab1: np.ndarray, lab2: np.ndarray) -> float:
    """ë‘ LAB íŒ”ë ˆíŠ¸ ê°„ì˜ í‰ê·  ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return np.mean(np.linalg.norm(np.array(lab1) - np.array(lab2), axis=1))

def get_top_similar_images(ref_lab: np.ndarray, all_data: list, top_n: int = 3, exclude: list = []) -> list:
    """ì°¸ì¡° íŒ”ë ˆíŠ¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
    candidates = [e for e in all_data if re.search(r'A \(\d+\)_2.png$', e['name']) and e['raw'] not in exclude]
    dists = [(calc_distance(ref_lab, e['lab']), e) for e in candidates]
    dists.sort(key=lambda x: x[0])
    return dists[:top_n]


# ===================================================================
# ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© í•¨ìˆ˜
# ===================================================================

@st.cache_resource
def load_sam_predictor(model_path: str) -> SamPredictor:
    """MobileSAM ëª¨ë¸ì„ ë¡œë“œí•˜ê³  Predictorë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (í´ë¼ìš°ë“œ ë°°í¬ë¥¼ ìœ„í•´ ë‹¤ìš´ë¡œë“œ ë¡œì§ ìœ ì§€)"""
    if not os.path.exists(model_path):
        with st.spinner("â˜ï¸ AI ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ)"):
            url = "https://github.com/ChaoningZhang/MobileSAM/raw/refs/heads/master/weights/mobile_sam.pt"
            try:
                response = requests.get(url, stream=True)
                response.raise_for_status()
                with open(model_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
            except requests.exceptions.RequestException as e:
                st.error(f"ğŸš¨ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.stop()
    model_type = "vit_t"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    mobile_sam = sam_model_registry[model_type](checkpoint=model_path)
    mobile_sam.to(device=device)
    mobile_sam.eval()
    return SamPredictor(mobile_sam)

@st.cache_data
def load_all_json_data(json_path: str) -> dict:
    """ì¶”ì²œì„ ìœ„í•œ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# ===================================================================
# UI ì»´í¬ë„ŒíŠ¸ í•¨ìˆ˜
# ===================================================================

def display_area_selection(predictor, image, image_np):
    """ì˜ì—­ ì„ íƒ UIë¥¼ í‘œì‹œí•˜ê³ , ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    st.info("ğŸ‘‡ ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒì„ ì¶”ì¶œí•  ì˜ì—­ì„ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”.")
    canvas_result = st_canvas(
        fill_color="rgba(255, 0, 0, 0.3)",
        background_image=image,
        height=image.height,
        width=image.width,
        drawing_mode="point",
        key="canvas",
    )

    if canvas_result.json_data and canvas_result.json_data["objects"]:
        points = [(obj["left"], obj["top"]) for obj in canvas_result.json_data["objects"]]
        if points:
            masks, _, _ = predictor.predict(np.array(points), np.ones(len(points)), multimask_output=False)
            st.session_state.mask = masks[0]

    if st.button("âœ… ì´ ì˜ì—­ìœ¼ë¡œ ë¶„ì„ ë° ì¶”ì²œ ì‹¤í–‰", type="primary"):
        if "mask" in st.session_state and st.session_state.mask is not None:
            with st.spinner("ìƒ‰ìƒ ë¶„ì„ ë° ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘..."):
                image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
                norm_image = normalize_brightness(image_bgr)
                input_lab_palette = extract_lab_palette(norm_image, st.session_state.mask)
                
                # ë¶„ì„ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥í•˜ê³ , ì•±ì„ ì¬ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ í™”ë©´ìœ¼ë¡œ ì „í™˜
                st.session_state.results = {
                    "input_palette_img": create_palette_image(input_lab_palette),
                    "recommendations": get_top_similar_images(input_lab_palette, load_all_json_data(JSON_PATH))
                }
                st.rerun()
        else:
            st.warning("ë¨¼ì € ìœ„ ì´ë¯¸ì§€ì—ì„œ ì˜ì—­ì„ í´ë¦­í•˜ì—¬ ì„ íƒí•´ì£¼ì„¸ìš”!")

def display_results():
    """ë¶„ì„ ë° ì¶”ì²œ ê²°ê³¼ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    st.write("---")
    st.header("âœ¨ ë¶„ì„ ê²°ê³¼")

    results = st.session_state.results
    st.subheader("ì¶”ì¶œëœ ìƒ‰ìƒ íŒ”ë ˆíŠ¸")
    st.image(results["input_palette_img"], channels="BGR")
    
    st.subheader("ìœ ì‚¬ ì´ë¯¸ì§€ ì¶”ì²œ")
    cols = st.columns(3)
    for i, col in enumerate(cols):
        with col:
            if i < len(results["recommendations"]):
                dist, entry = results["recommendations"][i]
                raw_name = entry['raw']
                folder = 'data/raw_apt' if raw_name.startswith("A") else 'data/raw_child'
                img_path = os.path.join(folder, raw_name)
                
                if os.path.exists(img_path):
                    rec_image = Image.open(img_path)
                    st.image(rec_image, caption=f"ìœ ì‚¬ë„ ì ìˆ˜: {dist:.2f}")
                else:
                    st.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}")
    
    if st.button("ë‹¤ì‹œ ë¶„ì„í•˜ê¸°"):
        # ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ê³  ì•±ì„ ì¬ì‹¤í–‰í•˜ì—¬ ì²˜ìŒ í™”ë©´ìœ¼ë¡œ ëŒì•„ê°
        st.session_state.results = None
        st.session_state.mask = None
        st.rerun()

# ===================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===================================================================

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ë¡œì§"""
    st.set_page_config(layout="wide")
    st.title("ğŸ¨ ë‹¨ì¼ ì´ë¯¸ì§€ ì»¬ëŸ¬ ë¶„ì„ ì‹œìŠ¤í…œ (ë¦¬íŒ©í† ë§ ë²„ì „)")

    # ëª¨ë¸/ë°ì´í„° ë¡œë”©ì€ í•œë²ˆë§Œ ì‹¤í–‰ë¨
    predictor = load_sam_predictor(MODEL_PATH)
    
    # ìƒíƒœ ì´ˆê¸°í™”
    if "results" not in st.session_state:
        st.session_state.results = None

    if st.session_state.results:
        # ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê²°ê³¼ í‘œì‹œ UI í˜¸ì¶œ
        display_results()
    else:
        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì˜ì—­ ì„ íƒ UI í˜¸ì¶œ
        st.header(f"ë¶„ì„ ëŒ€ìƒ ì´ë¯¸ì§€: `{IMAGE_PATH}`")
        if not os.path.exists(IMAGE_PATH):
            st.error(f"'{IMAGE_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        image = Image.open(IMAGE_PATH).convert("RGB")
        image_np = np.array(image)
        predictor.set_image(image_np)
        display_area_selection(predictor, image, image_np)

if __name__ == "__main__":
    main()