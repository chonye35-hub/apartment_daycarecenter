# final_app.py

import streamlit as st
import cv2
import numpy as np
from sklearn.cluster import KMeans
import torch
from PIL import Image
import os
import json
import re
import requests

# --- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from mobile_sam import sam_model_registry, SamPredictor
from streamlit_cropper import st_cropper

# --- 2. ìƒìˆ˜ ì •ì˜ ---
IMAGE_PATH = "input.jpg"
MODEL_PATH = "mobile_sam.pt"
JSON_PATH = "colors_lab.json"

# ===================================================================
# í—¬í¼ í•¨ìˆ˜ (Helper Functions)
# ===================================================================

def normalize_brightness(image_bgr: np.ndarray) -> np.ndarray:
    """HSV ìƒ‰ìƒ ê³µê°„ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ë°ê¸°ë¥¼ í‰íƒ„í™”í•©ë‹ˆë‹¤."""
    image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(image_hsv)
    v_eq = cv2.equalizeHist(v)
    image_hsv_eq = cv2.merge([h, s, v_eq])
    return cv2.cvtColor(image_hsv_eq, cv2.COLOR_HSV2BGR)

def extract_lab_palette(image_bgr: np.ndarray, mask: np.ndarray, n_colors: int = 5) -> np.ndarray:
    """ë§ˆìŠ¤í¬ ì˜ì—­ì—ì„œ LAB ìƒ‰ìƒ íŒ”ë ˆíŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    pixels_in_mask = image_bgr[mask]
    if len(pixels_in_mask) == 0:
        raise ValueError("ë§ˆìŠ¤í¬ ì˜ì—­ì— í”½ì…€ì´ ì—†ìŠµë‹ˆë‹¤.")
    masked_lab = cv2.cvtColor(pixels_in_mask.reshape(-1, 1, 3), cv2.COLOR_BGR2Lab).reshape(-1, 3)
    kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)
    kmeans.fit(masked_lab)
    return kmeans.cluster_centers_

def create_palette_image(lab_colors: np.ndarray, block_size: tuple = (50, 50)) -> np.ndarray:
    """LAB ìƒ‰ìƒ ë°°ì—´ë¡œ íŒ”ë ˆíŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    bgr_colors = []
    for c in lab_colors:
        L, a, b = np.clip(c, 0, 255)
        lab_pixel = np.uint8([[[L, a, b]]])
        bgr = cv2.cvtColor(lab_pixel, cv2.COLOR_Lab2BGR)[0, 0]
        bgr_colors.append(bgr)
    h, w = block_size[1], block_size[0] * len(bgr_colors)
    palette_img = np.zeros((h, w, 3), dtype=np.uint8)
    for i, color in enumerate(bgr_colors):
        palette_img[:, i * block_size[0]:(i + 1) * 100] = color
    return palette_img

def calc_distance(lab1: np.ndarray, lab2: np.ndarray) -> float:
    """ë‘ LAB íŒ”ë ˆíŠ¸ ê°„ì˜ í‰ê·  ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return np.mean(np.linalg.norm(np.array(lab1) - np.array(lab2), axis=1))

def get_top_similar_images(ref_lab: np.ndarray, all_data: list, top_n: int = 3) -> list:
    """ì°¸ì¡° íŒ”ë ˆíŠ¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
    candidates = [e for e in all_data if re.search(r'A \(\d+\)_2.png$', e['name'])]
    dists = [(calc_distance(ref_lab, e['lab']), e) for e in candidates]
    dists.sort(key=lambda x: x[0])
    return dists[:top_n]


# ===================================================================
# ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© í•¨ìˆ˜
# ===================================================================

@st.cache_resource
def load_sam_predictor(model_path: str) -> SamPredictor:
    """MobileSAM ëª¨ë¸ì„ ë¡œë“œí•˜ê³  Predictorë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (í´ë¼ìš°ë“œ ë°°í¬ë¥¼ ìœ„í•´ ë‹¤ìš´ë¡œë“œ ë¡œì§ ìœ ì§€)"""
    if not os.path.exists(model_path):
        with st.spinner("â˜ï¸ AI ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ)"):
            url = "https://github.com/ChaoningZhang/MobileSAM/raw/refs/heads/master/weights/mobile_sam.pt"
            try:
                response = requests.get(url, stream=True)
                response.raise_for_status()
                with open(model_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
            except requests.exceptions.RequestException as e:
                st.error(f"ğŸš¨ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.stop()
    model_type = "vit_t"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    mobile_sam = sam_model_registry[model_type](checkpoint=model_path)
    mobile_sam.to(device=device)
    mobile_sam.eval()
    return SamPredictor(mobile_sam)

@st.cache_data
def load_all_json_data(json_path: str) -> dict:
    """ì¶”ì²œì„ ìœ„í•œ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# ===================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===================================================================
def main():
    st.set_page_config(layout="wide")
    st.title("ğŸ¨ AI ì´ë¯¸ì§€ ì˜ì—­ ë¶„ì„ ë° ì¶”ì²œ ì‹œìŠ¤í…œ")

    # ëª¨ë¸/ë°ì´í„° ë¡œë”©
    predictor = load_sam_predictor(MODEL_PATH)
    all_data = load_all_json_data(JSON_PATH)

    # ìƒíƒœ ì´ˆê¸°í™”
    if "results" not in st.session_state:
        st.session_state.results = None
    if "box" not in st.session_state:
        st.session_state.box = None

    st.header(f"ë¶„ì„ ëŒ€ìƒ ì´ë¯¸ì§€: `{IMAGE_PATH}`")
    if not os.path.exists(IMAGE_PATH):
        st.error(f"'{IMAGE_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
        
    image = Image.open(IMAGE_PATH).convert("RGB")
    image_np = np.array(image)
    predictor.set_image(image_np)
    
    st.info("ğŸ‘‡ ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ ë¶„ì„í•  ì˜ì—­ì„ ì‚¬ê°í˜•ìœ¼ë¡œ ê·¸ë ¤ì£¼ì„¸ìš”.")
    
    # st_cropper ìœ„ì ¯ì„ ì‚¬ìš©. return_typeì„ 'box'ë¡œ ì„¤ì •í•˜ì—¬ ì¢Œí‘œë¥¼ ë°›ìŒ
    box = st_cropper(image, realtime_update=True, box_color='red', aspect_ratio=None,
                     return_type='box')
    
    # ì‚¬ìš©ìê°€ ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ë©´, st.session_stateì— ì¢Œí‘œë¥¼ ì €ì¥
    st.session_state.box = box

    if st.button("âœ… ì´ ì˜ì—­ìœ¼ë¡œ SAM ë¶„ì„ ë° ì¶”ì²œ ì‹¤í–‰", type="primary"):
        if st.session_state.box and st.session_state.box['width'] > 0 and st.session_state.box['height'] > 0:
            with st.spinner("SAMì´ ì˜ì—­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # st_cropperê°€ ë°˜í™˜í•œ box ì¢Œí‘œë¥¼ SAMì˜ input_box í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                # [x1, y1, x2, y2]
                input_box = np.array([
                    st.session_state.box['left'],
                    st.session_state.box['top'],
                    st.session_state.box['left'] + st.session_state.box['width'],
                    st.session_state.box['top'] + st.session_state.box['height']
                ])
                
                # SAM Predictor ì‹¤í–‰!
                masks, _, _ = predictor.predict(
                    point_coords=None,
                    point_labels=None,
                    box=input_box[None, :], # ë°•ìŠ¤ ì…ë ¥ì„ ìœ„í•´ ì°¨ì› ì¶”ê°€
                    multimask_output=False,
                )
                
                # SAMì´ ì°¾ì•„ë‚¸ ë§ˆìŠ¤í¬ë¡œ íŒ”ë ˆíŠ¸ ì¶”ì¶œ
                mask = masks[0]
                image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
                norm_image = normalize_brightness(image_bgr)
                input_lab_palette = extract_lab_palette(norm_image, mask)
                
                # ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
                st.session_state.results = {
                    "input_palette_img": create_palette_image(input_lab_palette),
                    "recommendations": get_top_similar_images(input_lab_palette, all_data),
                    "mask_display": cv2.addWeighted(image_np, 0.7, np.dstack([mask*0, mask*0, mask*255]).astype(np.uint8), 0.3, 0)
                }
                st.rerun() # ì•±ì„ ì¬ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ í™”ë©´ í‘œì‹œ
        else:
            st.warning("ë¨¼ì € ì´ë¯¸ì§€ ìœ„ì—ì„œ ë¶„ì„í•  ì˜ì—­ì„ ê·¸ë ¤ì£¼ì„¸ìš”.")

    if st.session_state.results:
        st.write("---")
        st.header("âœ¨ ë¶„ì„ ê²°ê³¼")
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("SAMì´ ì¸ì‹í•œ ì˜ì—­")
            st.image(st.session_state.results["mask_display"])
        with col2:
            st.subheader("ì¶”ì¶œëœ ìƒ‰ìƒ íŒ”ë ˆíŠ¸")
            st.image(st.session_state.results["input_palette_img"], channels="BGR")
        
        st.subheader("ìœ ì‚¬ ì´ë¯¸ì§€ ì¶”ì²œ")
        cols = st.columns(3)
        for i, col in enumerate(cols):
            with col:
                if i < len(st.session_state.results["recommendations"]):
                    dist, entry = st.session_state.results["recommendations"][i]
                    raw_name = entry['raw']
                    folder = 'data/raw_apt' if raw_name.startswith("A") else 'data/raw_child'
                    img_path = os.path.join(folder, raw_name)
                    
                    if os.path.exists(img_path):
                        rec_image = Image.open(img_path)
                        st.image(rec_image, caption=f"ìœ ì‚¬ë„ ì ìˆ˜: {dist:.2f}")
                    else:
                        st.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}")
        
        if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state.results = None
            st.rerun()

if __name__ == "__main__":
    main()