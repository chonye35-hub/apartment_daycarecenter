# final_app.py

import streamlit as st
import cv2
import numpy as np
from sklearn.cluster import KMeans
import torch
from PIL import Image
import os
import json
import re
import requests

# --- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from mobile_sam import sam_model_registry, SamPredictor
from streamlit_cropper import st_cropper

# --- 2. ìƒìˆ˜ ì •ì˜ ---
IMAGE_PATH = "input.jpg"
MODEL_PATH = "mobile_sam.pt"
JSON_PATH = "colors_lab.json"
RAW_APT_FOLDER = 'data/raw_apt'
RAW_CHILD_FOLDER = 'data/raw_child'

# ===================================================================
# í—¬í¼ í•¨ìˆ˜ (Helper Functions)
# ===================================================================

def normalize_brightness(image_bgr: np.ndarray) -> np.ndarray:
    """HSV ìƒ‰ìƒ ê³µê°„ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ë°ê¸°ë¥¼ í‰íƒ„í™”í•©ë‹ˆë‹¤."""
    image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(image_hsv)
    v_eq = cv2.equalizeHist(v)
    image_hsv_eq = cv2.merge([h, s, v_eq])
    return cv2.cvtColor(image_hsv_eq, cv2.COLOR_HSV2BGR)

def extract_lab_palette(image_bgr: np.ndarray, mask: np.ndarray, n_colors: int = 5) -> np.ndarray:
    """ë§ˆìŠ¤í¬ ì˜ì—­ì—ì„œ LAB ìƒ‰ìƒ íŒ”ë ˆíŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    pixels_in_mask = image_bgr[mask]
    if len(pixels_in_mask) == 0:
        raise ValueError("ë§ˆìŠ¤í¬ ì˜ì—­ì— í”½ì…€ì´ ì—†ìŠµë‹ˆë‹¤.")
    masked_lab = cv2.cvtColor(pixels_in_mask.reshape(-1, 1, 3), cv2.COLOR_BGR2Lab).reshape(-1, 3)
    kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)
    kmeans.fit(masked_lab)
    return kmeans.cluster_centers_

def create_palette_image(lab_colors: np.ndarray, block_size: tuple = (50, 50)) -> np.ndarray:
    """LAB ìƒ‰ìƒ ë°°ì—´ë¡œ íŒ”ë ˆíŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    bgr_colors = []
    for c in lab_colors:
        L, a, b = np.clip(c, 0, 255)
        lab_pixel = np.uint8([[[L, a, b]]])
        bgr = cv2.cvtColor(lab_pixel, cv2.COLOR_Lab2BGR)[0, 0]
        bgr_colors.append(bgr)
    h, w = block_size[1], block_size[0] * len(bgr_colors)
    palette_img = np.zeros((h, w, 3), dtype=np.uint8)
    for i, color in enumerate(bgr_colors):
        palette_img[:, i * block_size[0]:(i + 1) * 100] = color
    return palette_img

def calc_distance(lab1: np.ndarray, lab2: list) -> float:
    """ë‘ LAB íŒ”ë ˆíŠ¸ ê°„ì˜ í‰ê·  ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return np.mean(np.linalg.norm(np.array(lab1) - np.array(lab2), axis=1))

def get_top_similar_images(ref_lab: np.ndarray, all_data: list, suffix: str = r'_2.png$', top_n: int = 3, exclude: list = []) -> list:
    """ì°¸ì¡° íŒ”ë ˆíŠ¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
    candidates = [entry for entry in all_data if re.search(suffix, entry['name']) and entry['raw'] not in exclude]
    dists = [(calc_distance(ref_lab, entry['lab']), entry) for entry in candidates]
    dists.sort(key=lambda x: x[0])
    return dists[:top_n]

# ===================================================================
# ë°ì´í„° ë° ëª¨ë¸ ë¡œë”© í•¨ìˆ˜
# ===================================================================

@st.cache_resource
def load_sam_predictor(model_path: str) -> SamPredictor:
    """MobileSAM ëª¨ë¸ì„ ë¡œë“œí•˜ê³  Predictorë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (í´ë¼ìš°ë“œ ë°°í¬ë¥¼ ìœ„í•´ ë‹¤ìš´ë¡œë“œ ë¡œì§ ìœ ì§€)"""
    if not os.path.exists(model_path):
        with st.spinner("â˜ï¸ AI ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ)"):
            url = "https://github.com/ChaoningZhang/MobileSAM/raw/refs/heads/master/weights/mobile_sam.pt"
            try:
                response = requests.get(url, stream=True)
                response.raise_for_status()
                with open(model_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
            except requests.exceptions.RequestException as e:
                st.error(f"ğŸš¨ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.stop()
    model_type = "vit_t"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    mobile_sam = sam_model_registry[model_type](checkpoint=model_path)
    mobile_sam.to(device=device)
    mobile_sam.eval()
    return SamPredictor(mobile_sam)

@st.cache_data
def load_all_json_data(json_path: str) -> dict:
    """ì¶”ì²œì„ ìœ„í•œ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# ===================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===================================================================
def main():
    st.set_page_config(layout="wide")
    st.title("ğŸ¨ AI ê¸°ë°˜ ì´ë¯¸ì§€ íƒìƒ‰ ë° ì¶”ì²œ ì‹œìŠ¤í…œ")

    # ëª¨ë¸/ë°ì´í„° ë¡œë”©
    predictor = load_sam_predictor(MODEL_PATH)
    all_data = load_all_json_data(JSON_PATH)

    # ìƒíƒœ ì´ˆê¸°í™”
    if "results" not in st.session_state:
        st.session_state.results = None
    if "box" not in st.session_state:
        st.session_state.box = None
    
    # 1. ì˜ì—­ ì„ íƒ ë‹¨ê³„
    if not st.session_state.results:
        st.header(f"ë¶„ì„ ëŒ€ìƒ ì´ë¯¸ì§€: `{IMAGE_PATH}`")
        if not os.path.exists(IMAGE_PATH):
            st.error(f"'{IMAGE_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
            
        image = Image.open(IMAGE_PATH).convert("RGB")
        image_np = np.array(image)
        predictor.set_image(image_np)
        
        st.info("ğŸ‘‡ ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ ë¶„ì„í•  ì˜ì—­ì„ ì‚¬ê°í˜•ìœ¼ë¡œ ê·¸ë ¤ì£¼ì„¸ìš”.")
        
        box = st_cropper(image, realtime_update=True, box_color='red', aspect_ratio=None, return_type='box')
        st.session_state.box = box

        if st.button("âœ… ì´ ì˜ì—­ìœ¼ë¡œ ë¶„ì„ ë° ì¶”ì²œ ì‹¤í–‰", type="primary"):
            if st.session_state.box and st.session_state.box['width'] > 0:
                with st.spinner("SAM ë¶„ì„ ë° 1ì°¨ ì¶”ì²œ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘..."):
                    input_box = np.array([box['left'], box['top'], box['left'] + box['width'], box['top'] + box['height']])
                    masks, _, _ = predictor.predict(box=input_box[None, :], multimask_output=False)
                    mask = masks[0]
                    
                    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
                    norm_image = normalize_brightness(image_bgr)
                    input_lab_palette = extract_lab_palette(norm_image, mask)
                    
                    # 1ì°¨ ì¶”ì²œ (A ì‹œë¦¬ì¦ˆë§Œ)
                    first_recs = get_top_similar_images(input_lab_palette, all_data, suffix=r'A \(\d+\)_2.png$', top_n=3)
                    
                    st.session_state.results = {
                        "input_palette_img": create_palette_image(input_lab_palette),
                        "recommendations": first_recs,
                        "mask_display": cv2.addWeighted(image_np, 0.7, np.dstack([mask*0, mask*0, mask*255]).astype(np.uint8), 0.3, 0),
                        "prev_round_raws": [e['raw'] for _, e in first_recs]
                    }
                    st.rerun()
            else:
                st.warning("ë¨¼ì € ì´ë¯¸ì§€ ìœ„ì—ì„œ ë¶„ì„í•  ì˜ì—­ì„ ê·¸ë ¤ì£¼ì„¸ìš”.")
    
    # 2. ê²°ê³¼ í‘œì‹œ ë° ì¬ì¶”ì²œ ë‹¨ê³„
    if st.session_state.results:
        st.header("âœ¨ ë¶„ì„ ê²°ê³¼")
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("SAMì´ ì¸ì‹í•œ ì˜ì—­")
            st.image(st.session_state.results["mask_display"])
        with col2:
            st.subheader("ì¶”ì¶œëœ ìƒ‰ìƒ íŒ”ë ˆíŠ¸")
            st.image(st.session_state.results["input_palette_img"], channels="BGR")
        
        st.write("---")
        st.subheader("ìœ ì‚¬ ì´ë¯¸ì§€ ì¶”ì²œ")
        st.info("ì¶”ì²œëœ ì´ë¯¸ì§€ ì•„ë˜ì˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì—°ê´€ ì¶”ì²œì„ ê³„ì† íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        cols = st.columns(3)
        recs = st.session_state.results["recommendations"]
        for i, col in enumerate(cols):
            with col:
                if i < len(recs):
                    dist, entry = recs[i]
                    raw_name = entry['raw']
                    folder = RAW_APT_FOLDER if raw_name.startswith("A") else RAW_CHILD_FOLDER
                    img_path = os.path.join(folder, raw_name)
                    
                    if os.path.exists(img_path):
                        rec_image = Image.open(img_path)
                        st.image(rec_image, caption=f"ìœ ì‚¬ë„ ì ìˆ˜: {dist:.2f}")

                        if st.button(f"ì´ê²ƒê³¼ ë¹„ìŠ·í•œ ê²ƒ ë” ë³´ê¸°", key=f"rec_{i}"):
                            with st.spinner("ì—°ê´€ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ íƒìƒ‰í•©ë‹ˆë‹¤..."):
                                new_ref_lab = entry['lab']
                                exclude_list = st.session_state.results["prev_round_raws"]
                                
                                # ì¬ì¶”ì²œ ì‹œì—ëŠ” ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•¨ (suffix ê¸°ë³¸ê°’ ì‚¬ìš©)
                                new_recs = get_top_similar_images(new_ref_lab, all_data, top_n=3, exclude=exclude_list)
                                
                                st.session_state.results["recommendations"] = new_recs
                                st.session_state.results["prev_round_raws"] = [e['raw'] for _, e in new_recs]
                                st.rerun()
                    else:
                        st.warning(f"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}")
        
        st.write("---")
        if st.button("â†©ï¸ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state.results = None
            st.rerun()

if __name__ == "__main__":
    main()